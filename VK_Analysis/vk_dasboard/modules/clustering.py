
import numpy as np # –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞, –º–∞—Å—Å–∏–≤—ã
import pandas as pd  # —Ç–∞–±–ª–∏—Ü—ã –∫—Ä–∞—Å–∏–≤—ã–µ
import streamlit as st # –±–∏–±–ª–∞ –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ—Å–∞
import plotly.express as px # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏

from pathlib import Path # –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
from io import BytesIO# –ß—Ç–µ–Ω–∏–µ CSV –∏–∑ –±–∞–π—Ç–æ–≤

# Sklearn: –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ + –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
from sklearn.compose import ColumnTransformer #
from sklearn.preprocessing import OneHotEncoder, StandardScaler #
from sklearn.cluster import MiniBatchKMeans, DBSCAN #
from sklearn.metrics import silhouette_score # —Å–∏–ª—É–µ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–ª-–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫-means

import umap


# ============================================================
# CONFIG
# ============================================================

# –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã

DEFAULT_DATA_PATHS = [              # –∏—â—É –æ—Ç–∫—É–¥–∞ –ø–æ–¥—Ç—è–Ω—É—Ç—å csv —Å –¥–∞–Ω–Ω—ã–º–∏
    Path("vk_users_10000.csv"),
    Path("data/vk_users_10000.csv"),
    Path("datasets/vk_users_10000.csv"),
]

DROP_COLS = {"id", "synthetic_cluster", "cluster_kmeans", "cluster_dbscan"}
NUM_COLS_CANDIDATES = ["age"]


# ============================================================
# –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–æ–±—Ä–∞–±–æ—Ç–∫–∞
# ============================================================

# —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É –¥–∞–¥–∞—Å–µ—Ç—É
def find_default_csv() -> Path | None:
    for p in DEFAULT_DATA_PATHS:
        if p.exists():
            return p
    return None


# —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Ä–∞–∑–Ω—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ sklearn --> —ç–∫–∑–µ–º–ø–ª—è—Ä OneHot —Å–æ–∑–¥–∞—Å—Ç—Å—è –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
def safe_onehot():
    try:
        return OneHotEncoder(handle_unknown="ignore", sparse_output=True)
    except TypeError:
        return OneHotEncoder(handle_unknown="ignore", sparse=True)

# –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –Ω—É–∂–µ–Ω –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∫–∏ –≤ Streamlit
@st.cache_data(show_spinner=False) # ‚Üê –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –≤ Streamlit
def read_csv_from_path(path: str) -> pd.DataFrame:
    return pd.read_csv(path, encoding="utf-8-sig") # –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame


@st.cache_data(show_spinner=False)
def read_csv_from_bytes(b: bytes) -> pd.DataFrame:
    return pd.read_csv(BytesIO(b), encoding="utf-8-sig")


# —Ä–∞–∑–¥–µ–ª—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
def detect_columns(df: pd.DataFrame):
    num_cols = [c for c in NUM_COLS_CANDIDATES if c in df.columns] # —Ç—É—Ç —á–∏—Å–ª–æ–≤—ã–µ
    cat_cols = [c for c in df.columns if c not in DROP_COLS and c not in num_cols]
    cat_cols = [c for c in cat_cols if df[c].dtype == "object"] # —Ç—É—Ç –ª–µ–∂–∞—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ
    return num_cols, cat_cols

# –∫–µ—à–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç - —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ñ—É–Ω–∫—Ü–∏–∏
#@st.cache_resource(show_spinner=False)
def fit_preprocessor(df: pd.DataFrame, num_cols, cat_cols) -> ColumnTransformer:
    pre = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), num_cols), # —Å—Ç—Ä–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–µ—É–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            ("cat", safe_onehot(), cat_cols), # –≤–∞–Ω —Ö–æ—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö
        ],
        remainder="drop",
    )
    pre.fit(df) # –∑–∞–ø—É—Å–∫ –º–µ—Ç–æ–¥–æ–≤
    return pre


# –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–≤–∞–Ω—Ö–æ—Ç, —Å–∫–∞–ª–µ—Ä –∏ —Ç–¥)
#@st.cache_resource(show_spinner=False)
def transform_features(_pre: ColumnTransformer, df: pd.DataFrame):
    return _pre.transform(df)


# ============================================================
# Risk / Explanation helpers
# ============================================================
def share_positive(series: pd.Series) -> float:
    """–î–æ–ª—è '–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ' –æ—Ç–Ω–æ—à–µ–Ω–∏—è."""
    if series is None or series.empty:
        return 0.0
    s = series.fillna("").astype(str).str.lower()
    return float(s.str.contains("–ø–æ–ª–æ–∂").mean())


def share_is(series: pd.Series, keywords: list[str]) -> float:
    """–î–æ–ª—è —Å—Ç—Ä–æ–∫, –≥–¥–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ."""
    if series is None or series.empty:
        return 0.0
    s = series.fillna("").astype(str).str.lower()
    mask = False
    for kw in keywords:
        mask = mask | s.str.contains(kw)
    return float(mask.mean())


def ideological_risk_share(series: pd.Series) -> float:
    """
    –ò–¥–µ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∏—Å–∫ (–¥–ª—è —Ä–µ–∂–∏–º–Ω–æ–≥–æ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è):
    –ª–∏–±–µ—Ä–∞–ª—å–Ω—ã–µ / –ª–∏–±–µ—Ä—Ç–∞—Ä–∏–∞–Ω—Å–∫–∏–µ / –∏–Ω–¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ç–Ω—ã–µ.
    """
    if series is None or series.empty:
        return 0.0
    s = series.fillna("").astype(str).str.lower()
    return float(
        (s.str.contains("–ª–∏–±–µ—Ä–∞–ª") | s.str.contains("–ª–∏–±–µ—Ä—Ç–∞—Ä–∏–∞–Ω") | s.str.contains("–∏–Ω–¥–∏—Ñ—Ñ–µ—Ä")).mean()
    )


def top_value(series: pd.Series) -> str:
    if series is None or series.empty:
        return "‚Äî"
    vc = series.fillna("‚Äî").astype(str).value_counts()
    return str(vc.index[0])


def top_n(series: pd.Series, n=3) -> str:
    if series is None or series.empty:
        return "‚Äî"
    vc = series.fillna("").astype(str).value_counts(normalize=True).head(n)
    items = []
    for name, share in vc.items():
        if name == "":
            continue
        items.append(f"{name} ({share*100:.0f}%)")
    return ", ".join(items) if items else "‚Äî"


def risk_drivers(part: pd.DataFrame) -> dict:
    """–°—á–∏—Ç–∞–µ–º –¥–æ–ª–∏ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–∏—Å–∫–∞ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ."""
    alc_pos = share_positive(part["alcohol"]) if "alcohol" in part.columns else 0.0
    smk_pos = share_positive(part["smoking"]) if "smoking" in part.columns else 0.0

    edu_low = share_is(part["education_level"], ["–Ω–µ—Ç", "—Å—Ä–µ–¥–Ω–µ–µ"]) if "education_level" in part.columns else 0.0
    life_hed = share_is(part["main_in_life"], ["—Ä–∞–∑–≤–ª–µ—á", "—Å–ª–∞–≤–∞", "–≤–ª–∏—è–Ω–∏–µ"]) if "main_in_life" in part.columns else 0.0
    ppl_money = share_is(part["main_in_people"], ["–≤–ª–∞—Å—Ç—å", "–±–æ–≥–∞—Ç"]) if "main_in_people" in part.columns else 0.0

    pol_liberal = ideological_risk_share(part["political"]) if "political" in part.columns else 0.0

    return {
        "alc_pos": alc_pos,
        "smk_pos": smk_pos,
        "edu_low": edu_low,
        "life_hed": life_hed,
        "ppl_money": ppl_money,
        "pol_liberal": pol_liberal,
    }

#   —Ç—É—Ç –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∏–≤–∞—Ç—å —á—É–≤—Å–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã 
def risk_score_0_100(alc, smk, pol, edu):
    """
    –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∏—Å–∫ –∫–ª–∞—Å—Ç–µ—Ä–∞ (0‚Äì100).
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
    - –∞–ª–∫–æ–≥–æ–ª—å (45%)
    - –ª–∏–±–µ—Ä–∞–ª—å–Ω—ã–µ/–ª–∏–±–µ—Ä—Ç–∞—Ä–∏–∞–Ω—Å–∫–∏–µ/–∏–Ω–¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ç–Ω—ã–µ (25%)
    - –∫—É—Ä–µ–Ω–∏–µ (20%)
    - –Ω–∏–∑–∫–æ–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (10%)
    """
    return float(
        round(
            100 * (
                0.45 * alc +
                0.20 * smk +
                0.25 * pol +
                0.10 * edu
            ),
            1
        )
    )


def risk_level_ru(score: float) -> str:
    if score >= 60:
        return "–í–´–°–û–ö–ò–ô"
    if score >= 30:
        return "–°–†–ï–î–ù–ò–ô"
    return "–ù–ò–ó–ö–ò–ô"


def main_risk_factor(dr: dict) -> str:
    """
    –ì–ª–∞–≤–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Ä–∏—Å–∫–∞ ‚Äî –≤—ã–±–∏—Ä–∞–µ–º —Ñ–∞–∫—Ç–æ—Ä —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –≤–∫–ª–∞–¥–æ–º –≤ –∏—Ç–æ–≥–æ–≤—ã–π score.
    """
    factors = {
        "–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –∞–ª–∫–æ–≥–æ–ª—é": dr["alc_pos"] * 0.45,
        "–õ–∏–±–µ—Ä–∞–ª—å–Ω—ã–µ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –≤–∑–≥–ª—è–¥—ã": dr["pol_liberal"] * 0.25,
        "–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –∫—É—Ä–µ–Ω–∏—é": dr["smk_pos"] * 0.20,
        "–ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è": dr["edu_low"] * 0.10,
    }
    return max(factors, key=factors.get)


def why_danger_ru(alcohol_pos: float, smoking_pos: float, pol_liberal: float, edu_low: float, top_life: str) -> str:
    reasons = []
    if alcohol_pos >= 0.45:
        reasons.append("–≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ –∞–ª–∫–æ–≥–æ–ª—é")
    if smoking_pos >= 0.45:
        reasons.append("–≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ –∫—É—Ä–µ–Ω–∏—é")
    if pol_liberal >= 0.45:
        reasons.append("–ø—Ä–µ–æ–±–ª–∞–¥–∞–Ω–∏–µ –ª–∏–±–µ—Ä–∞–ª—å–Ω—ã—Ö/–ª–∏–±–µ—Ä—Ç–∞—Ä–∏–∞–Ω—Å–∫–∏—Ö/–∏–Ω–¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ç–Ω—ã—Ö –≤–∑–≥–ª—è–¥–æ–≤")
    if edu_low >= 0.45:
        reasons.append("–≤—ã—Å–æ–∫–∞—è –¥–æ–ª—è –Ω–∏–∑–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è")
    if isinstance(top_life, str) and (("—Ä–∞–∑–≤–ª–µ—á" in top_life.lower()) or ("—Å–ª–∞–≤–∞" in top_life.lower())):
        reasons.append("—Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Å–º–µ—â–µ–Ω—ã –≤ —Å—Ç–æ—Ä–æ–Ω—É —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏–π/–≤–ª–∏—è–Ω–∏—è")
    return "; ".join(reasons) if reasons else "–≤—ã—Ä–∞–∂–µ–Ω–Ω—ã—Ö —Ä–∏—Å–∫-—Ñ–∞–∫—Ç–æ—Ä–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"


def cluster_type_ru(dr: dict, top_edu: str, top_life: str) -> str:
    if dr["alc_pos"] > 0.50 and dr["pol_liberal"] > 0.40:
        return "–†–∏—Å–∫–æ–≤—ã–π: –∞–ª–∫–æ–≥–æ–ª—å + –∏–¥–µ–æ–ª–æ–≥–∏—è"
    if dr["alc_pos"] > 0.50:
        return "–†–∏—Å–∫–æ–≤—ã–π: –≤—Ä–µ–¥–Ω—ã–µ –ø—Ä–∏–≤—ã—á–∫–∏"
    if dr["pol_liberal"] > 0.50:
        return "–†–∏—Å–∫–æ–≤—ã–π: –∏–¥–µ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å"
    if dr["edu_low"] > 0.45:
        return "–†–∏—Å–∫–æ–≤—ã–π: –Ω–∏–∑–∫–æ–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"
    if "–≤—ã—Å—à" in str(top_edu).lower() and ("—Å–µ–º—å—è" in str(top_life).lower() or "—Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç" in str(top_life).lower()):
        return "–ù–∞–¥—ë–∂–Ω—ã–π: —Å–æ—Ü–∏–∞–ª—å–Ω–æ —É—Å—Ç–æ–π—á–∏–≤—ã–π"
    return "–°–º–µ—à–∞–Ω–Ω—ã–π: —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è"


def recommendation_ru(level: str) -> str:
    if level == "–í–´–°–û–ö–ò–ô":
        return "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≥–ª—É–±–ª—ë–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (—Å–æ–æ–±—â–µ—Å—Ç–≤–∞/–∫–æ–Ω—Ç–µ–Ω—Ç/–æ–∫—Ä—É–∂–µ–Ω–∏–µ)."
    if level == "–°–†–ï–î–ù–ò–ô":
        return "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ç–æ—á–µ—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–∞–Ω–æ–º–∞–ª–∏–∏, –æ–∫—Ä—É–∂–µ–Ω–∏–µ 1‚Äì2 —É—Ä–æ–≤–Ω—è)."
    return "–§–æ–Ω–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å (–±–µ–∑ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞)."


def build_text_report(summary_df: pd.DataFrame, total_n: int) -> str:
    lines = []
    lines.append("–û–¢–ß–Å–¢ –ü–û –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–ò –û–ö–†–£–ñ–ï–ù–ò–Ø –í–ö")
    lines.append("=" * 70)
    lines.append(f"–í—Å–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª–µ–π: {total_n}")
    lines.append("")

    for _, r in summary_df.iterrows():
        lines.append(f"–ö–ª–∞—Å—Ç–µ—Ä {r['–ö–ª–∞—Å—Ç–µ—Ä']} ‚Äî {r['–¢–∏–ø –∫–ª–∞—Å—Ç–µ—Ä–∞']}")
        lines.append(f"  –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {r['–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞']} | –†–∏—Å–∫: {r['–†–∏—Å–∫, % (0-100)']} / 100")
        lines.append(f"  –ì–ª–∞–≤–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Ä–∏—Å–∫–∞: {r['–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Ä–∏—Å–∫–∞']}")
        lines.append(f"  –†–∞–∑–º–µ—Ä: {r['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']} ({r['–î–æ–ª—è, %']}%)")
        lines.append(f"  –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {r['–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏']}")
        lines.append(f"  –ü–æ—á–µ–º—É –≤–∞–∂–µ–Ω: {r['–ü–æ—á–µ–º—É –≤–∞–∂–µ–Ω']}")
        lines.append(f"  –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {r['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è']}")
        lines.append(f"  –û—Å–Ω–æ–≤–Ω–æ–π –≥–æ—Ä–æ–¥: {r['–û—Å–Ω–æ–≤–Ω–æ–π –≥–æ—Ä–æ–¥']}")
        lines.append(f"  –û—Å–Ω–æ–≤–Ω–æ–π –≤—É–∑: {r['–û—Å–Ω–æ–≤–Ω–æ–π –≤—É–∑']}")
        lines.append("-" * 70)

    return "\n".join(lines)


# ============================================================
# —Å—Ç—Ä–∏–º–ª–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü–∞
# ============================================================
def page(card=None):
    st.markdown("## üß© –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –í–ö–æ–Ω—Ç–∞–∫—Ç–µ")

    # -------------------------
    # 1) –ê–≤—Ç–æ–∑–∞–≥—Ä—É–∑–∫–∞ CSV (–±–µ–∑ –ª–∏—à–Ω–µ–≥–æ file_uploader, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω)
    # -------------------------
    default_path = find_default_csv()
    df = None

    if default_path:
        df = read_csv_from_path(str(default_path))
        st.caption(f"–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: **{default_path.as_posix()}**")
    else:
        st.warning("–§–∞–π–ª vk_users_10000.csv –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –≤—Ä—É—á–Ω—É—é:")
        uploaded = st.file_uploader("CSV —Ñ–∞–π–ª", type=["csv"])
        if uploaded is None:
            return
        df = read_csv_from_bytes(uploaded.getvalue())

    # –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –ù–ï –ø–æ–∫–∞–∑—ã–≤–∞–µ–º

    # -------------------------
    # 2) –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏ X
    # -------------------------
    num_cols, cat_cols = detect_columns(df)
    df_proc = df.copy()
    for c in cat_cols:
        df_proc[c] = df_proc[c].fillna("")

    pre = fit_preprocessor(df_proc, num_cols, cat_cols)
    X = transform_features(pre, df_proc)

    st.markdown("### –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    total_n = len(df_proc)
    st.write(f"–í—Å–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª–µ–π: **{total_n:,}**")

    k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤", 2, 10, 4)

    # -------------------------
    # 3) KMeans
    # -------------------------
    with st.spinner("–í—ã–ø–æ–ª–Ω—è—é K-Means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é..."):
        km = MiniBatchKMeans(n_clusters=int(k), random_state=42, batch_size=1024)
        df_out = df.copy()
        df_out["cluster_kmeans"] = km.fit_predict(X).astype(int)

    # -------------------------
    # 4) UMAP
    # -------------------------
    with st.spinner("–°—Ç—Ä–æ—é UMAP-–ø—Ä–æ–µ–∫—Ü–∏—é..."):
        reducer = umap.UMAP(
            n_neighbors=25,
            min_dist=0.10,
            n_components=2,
            metric="cosine",
            random_state=42
        )
        emb = reducer.fit_transform(X)

    # -------------------------
    # 5) –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞
    # -------------------------
    summary_rows = []
    for cl in sorted(df_out["cluster_kmeans"].unique()):
        part = df_out[df_out["cluster_kmeans"] == cl]
        dr = risk_drivers(part)

        score = risk_score_0_100(dr["alc_pos"], dr["smk_pos"], dr["pol_liberal"], dr["edu_low"])
        lvl = risk_level_ru(score)

        top_city = top_value(part["city"]) if "city" in part.columns else "‚Äî"
        top_uni = top_value(part["university"]) if "university" in part.columns else "‚Äî"
        top_life = top_value(part["main_in_life"]) if "main_in_life" in part.columns else "‚Äî"
        top_people = top_value(part["main_in_people"]) if "main_in_people" in part.columns else "‚Äî"
        top_edu = top_value(part["education_level"]) if "education_level" in part.columns else "‚Äî"
        top_pol = top_value(part["political"]) if "political" in part.columns else "‚Äî"

        size = int(len(part))
        share_pct = (size / total_n) * 100.0

        # –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∫–æ—Ä–æ—Ç–∫–æ)
        key_facts = []
        key_facts.append(f"–∞–ª–∫+ {dr['alc_pos']*100:.0f}%")
        key_facts.append(f"–∫—É—Ä+ {dr['smk_pos']*100:.0f}%")
        key_facts.append(f"–ª–∏–±/–∏–Ω–¥–∏—Ñ {dr['pol_liberal']*100:.0f}%")
        key_facts.append(f"–Ω–∏–∑–∫.–æ–±—Ä {dr['edu_low']*100:.0f}%")
        key_facts = ", ".join(key_facts)

        ctype = cluster_type_ru(dr, str(top_edu), str(top_life))
        main_factor = main_risk_factor(dr)
        why = why_danger_ru(dr["alc_pos"], dr["smk_pos"], dr["pol_liberal"], dr["edu_low"], str(top_life))

        summary_rows.append({
            "–ö–ª–∞—Å—Ç–µ—Ä": int(cl),
            "–¢–∏–ø –∫–ª–∞—Å—Ç–µ—Ä–∞": ctype,
            "–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞": lvl,
            "–†–∏—Å–∫, % (0-100)": round(score, 1),
            "–î–æ–ª—è, %": round(share_pct, 2),
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": size,
            "–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Ä–∏—Å–∫–∞": main_factor,
            "–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏": key_facts,
            "–ü–æ—á–µ–º—É –≤–∞–∂–µ–Ω": why,
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è": recommendation_ru(lvl),
            "–û—Å–Ω–æ–≤–Ω–æ–π –≥–æ—Ä–æ–¥": str(top_city),
            "–û—Å–Ω–æ–≤–Ω–æ–π –≤—É–∑": str(top_uni),
            "–¶–µ–Ω–Ω–æ—Å—Ç–∏ (—Ç–æ–ø)": str(top_life),
            "–í –ª—é–¥—è—Ö (—Ç–æ–ø)": str(top_people),
            "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (—Ç–æ–ø)": str(top_edu),
            "–ü–æ–ª–∏—Ç–∏–∫–∞ (—Ç–æ–ø)": str(top_pol),
        })

    summary_df = pd.DataFrame(summary_rows)

    order = {"–í–´–°–û–ö–ò–ô": 2, "–°–†–ï–î–ù–ò–ô": 1, "–ù–ò–ó–ö–ò–ô": 0}
    summary_df["_ord"] = summary_df["–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞"].map(order).fillna(0).astype(int)
    summary_df = summary_df.sort_values(["_ord", "–†–∏—Å–∫, % (0-100)", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"], ascending=[False, False, False]).drop(columns=["_ord"])

    st.markdown("### –û–ø–µ—Ä–∞—Ç–∏–≤–Ω–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º")

    def style_summary(df: pd.DataFrame):
        def risk_color(val):
            if val == "–í–´–°–û–ö–ò–ô":
                return "color:#ef4444; font-weight:800;"
            if val == "–°–†–ï–î–ù–ò–ô":
                return "color:#eab308; font-weight:800;"
            return "color:#22c55e; font-weight:800;"

        sty = (
            df.style
            # –±–∞–∑–æ–≤—ã–π —Ñ–æ–Ω —Ç–∞–±–ª–∏—Ü—ã ‚Äî —á–∏—Å—Ç—ã–π —á—ë—Ä–Ω—ã–π
            .set_properties(**{
                "background-color": "#0b0f14",
                "color": "#e6edf3",
                "border-color": "#6d28d9",
                "font-size": "13px",
            })
            # —Ä–∞–º–∫–∏ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            .set_table_styles([
                # –í—Å—è —Ç–∞–±–ª–∏—Ü–∞
                {
                    "selector": "",
                    "props": [
                        ("border", "1px solid #6d28d9"),
                        ("border-radius", "12px"),
                    ]
                },
                # –ó–∞–≥–æ–ª–æ–≤–∫–∏
                {
                    "selector": "th",
                    "props": [
                        ("background-color", "#0b0f14"),
                        ("color", "#ffffff"),
                        ("border", "1px solid #6d28d9"),
                        ("font-weight", "800"),
                    ]
                },
                # –Ø—á–µ–π–∫–∏
                {
                    "selector": "td",
                    "props": [
                        ("background-color", "#0b0f14"),
                        ("border", "1px solid rgba(109,40,217,0.55)"),
                    ]
                },
                # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ —Å—Ç—Ä–æ–∫ –ø—Ä–∏ –Ω–∞–≤–µ–¥–µ–Ω–∏–∏
                {
                    "selector": "tbody tr:hover",
                    "props": [
                        ("background-color", "rgba(109,40,217,0.08)")
                    ]
                }
            ])
            # –¶–≤–µ—Ç —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞
            .map(risk_color, subset=["–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞"])
            # –ü–æ–ª–æ—Å–∞ —Ä–∏—Å–∫–∞ (–±–µ–∑ –º—É—Ç–Ω–æ–≥–æ —Ñ–æ–Ω–∞)
            .bar(subset=["–†–∏—Å–∫, % (0-100)"], color="#ef4444", vmin=0, vmax=100)
        )

        return sty

    st.dataframe(
        style_summary(summary_df[[
            "–ö–ª–∞—Å—Ç–µ—Ä", "–¢–∏–ø –∫–ª–∞—Å—Ç–µ—Ä–∞",
            "–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞", "–†–∏—Å–∫, % (0-100)",
            "–î–æ–ª—è, %", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ",
            "–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Ä–∏—Å–∫–∞",
            "–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏",
            "–ü–æ—á–µ–º—É –≤–∞–∂–µ–Ω",
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è",
            "–û—Å–Ω–æ–≤–Ω–æ–π –≥–æ—Ä–æ–¥", "–û—Å–Ω–æ–≤–Ω–æ–π –≤—É–∑"
        ]]),
        use_container_width=True
    )

    # -------------------------
    # 6) UMAP –≥—Ä–∞—Ñ–∏–∫ (SOC colors + –±–µ–ª–∞—è –ª–µ–≥–µ–Ω–¥–∞ + —Å–∫—Ä—ã—Ç—ã–µ –æ—Å–∏)
    # -------------------------
    risk_level_map = dict(zip(summary_df["–ö–ª–∞—Å—Ç–µ—Ä"], summary_df["–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞"]))
    risk_score_map = dict(zip(summary_df["–ö–ª–∞—Å—Ç–µ—Ä"], summary_df["–†–∏—Å–∫, % (0-100)"]))
    main_factor_map = dict(zip(summary_df["–ö–ª–∞—Å—Ç–µ—Ä"], summary_df["–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Ä–∏—Å–∫–∞"]))

    vis = df_out.copy()
    vis["umap_x"] = emb[:, 0]
    vis["umap_y"] = emb[:, 1]
    vis["–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞"] = vis["cluster_kmeans"].map(risk_level_map)
    vis["–†–∏—Å–∫, %"] = vis["cluster_kmeans"].map(risk_score_map)
    vis["–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Ä–∏—Å–∫–∞"] = vis["cluster_kmeans"].map(main_factor_map)

    color_map = {"–ù–ò–ó–ö–ò–ô": "#22c55e", "–°–†–ï–î–ù–ò–ô": "#eab308", "–í–´–°–û–ö–ò–ô": "#ef4444"}

    fig = px.scatter(
        vis,
        x="umap_x",
        y="umap_y",
        color="–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞",
        color_discrete_map=color_map,
        symbol="cluster_kmeans",
        opacity=0.88,
        hover_data=[c for c in [
            "cluster_kmeans", "–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞", "–†–∏—Å–∫, %", "–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Ä–∏—Å–∫–∞",
            "sex", "age", "city", "education_level", "university",
            "main_in_life", "main_in_people", "alcohol", "smoking", "political"
        ] if c in vis.columns],
        title="UMAP-–ø—Ä–æ–µ–∫—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ö–æ–¥—Å—Ç–≤–∞ –ø—Ä–æ—Ñ–∏–ª–µ–π)"
    )

    fig.update_layout(
        template="plotly_dark",
        height=760,
        paper_bgcolor="#0b0f14",
        plot_bgcolor="#0b0f14",
        font=dict(color="#e6edf3", size=14),
        legend=dict(
            title=dict(text="–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞", font=dict(color="#ffffff", size=14)),
            font=dict(color="#ffffff", size=13),
            bgcolor="rgba(0,0,0,0.35)",
            bordercolor="rgba(255,255,255,0.12)",
            borderwidth=1
        ),
        margin=dict(l=20, r=20, t=60, b=20),
    )

    # —Å–∫—Ä—ã–≤–∞—é "–Ω–µ–ø–æ–Ω—è—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã" –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    fig.update_xaxes(title="UMAP-–ø—Ä–æ–µ–∫—Ü–∏—è X", showgrid=False, zeroline=False, showticklabels=False)
    fig.update_yaxes(title="UMAP-–ø—Ä–æ–µ–∫—Ü–∏—è Y", showgrid=False, zeroline=False, showticklabels=False)

    st.plotly_chart(fig, use_container_width=True)
    st.caption("UMAP ‚Äî –º–µ—Ç–æ–¥ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏. –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã X/Y –Ω–µ –∏–º–µ—é—Ç —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ —Å–º—ã—Å–ª–∞ –∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ç–æ–ª—å–∫–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é –±–ª–∏–∑–æ—Å—Ç—å –ø—Ä–æ—Ñ–∏–ª–µ–π.")

    # -------------------------
    # 7) DBSCAN (—Å–∫—Ä—ã—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    # -------------------------
    show_dbscan = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–∏—Å–∫ –Ω–µ—Ç–∏–ø–∏—á–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π (DBSCAN)", value=False)
    if show_dbscan:
        st.markdown("### DBSCAN: –ø–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö/–Ω–µ—Ç–∏–ø–∏—á–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π")

        with st.expander("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã DBSCAN", expanded=False):
            eps = st.slider("eps", 0.05, 5.0, 0.60, 0.05)
            min_samples = st.slider("min_samples", 3, 30, 10)

        with st.spinner("–ó–∞–ø—É—Å–∫–∞—é DBSCAN –Ω–∞ UMAP..."):
            db = DBSCAN(eps=float(eps), min_samples=int(min_samples))
            labels_db = db.fit_predict(emb)

        noise_share = float((labels_db == -1).mean()) * 100.0

        if noise_share < 0.1:
            st.info("–ù–µ—Ç–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏ (—à—É–º) –Ω–µ –≤—ã—è–≤–ª–µ–Ω—ã –ø—Ä–∏ —Ç–µ–∫—É—â–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö.")
        else:
            st.write(f"–ê–Ω–æ–º–∞–ª–∏–∏ / —à—É–º (label=-1): **{noise_share:.1f}%**")
            st.dataframe(pd.Series(labels_db).value_counts().rename("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ").to_frame(), use_container_width=True)

    # -------------------------
    # 8) –≠–∫—Å–ø–æ—Ä—Ç (TXT –æ—Ç—á—ë—Ç + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ CSV)
    # -------------------------
    st.markdown("### –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")

    report_text = build_text_report(summary_df, total_n)

    st.markdown(
        """
        <div style="
            background:#0f1622;
            color:#e6edf3;
            border-radius:16px;
            padding:16px 18px;
            border:1px solid rgba(109,40,217,0.55);
            box-shadow: 0 10px 26px rgba(0,0,0,0.45);
            ">
          <div style="font-weight:800; font-size:14px; margin-bottom:8px; color:#ffffff;">
            üìÑ –≠–∫—Å–ø–æ—Ä—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
          </div>
          <div style="font-size:12px; opacity:.9; margin-bottom:12px;">
            –°–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, –¥–æ–ª–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –≥–ª–∞–≤–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Ä–∏—Å–∫–∞, –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ò–ë.
          </div>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.download_button(
        "–°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç (.txt)",
        data=report_text.encode("utf-8"),
        file_name="vk_clusters_report.txt",
        mime="text/plain",
        use_container_width=True
    )

    # ===============================
    # –≠–∫—Å–ø–æ—Ä—Ç CSV
    # ===============================

    df_export = df_out.copy()
    df_export["risk_score_0_100"] = df_export["cluster_kmeans"].map(risk_score_map)
    df_export["risk_level_ru"] = df_export["cluster_kmeans"].map(risk_level_map)
    df_export["main_risk_factor"] = df_export["cluster_kmeans"].map(main_factor_map)

    csv_bytes = df_export.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")

    st.markdown(
        """
        <div class="card accent-purple" style="margin-top:14px;">
            <div style="font-size:15px; font-weight:800; margin-bottom:8px;">
                 –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            </div>
            <div style="font-size:12px; opacity:.9; line-height:1.5; margin-bottom:12px;">
                CSV —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –ø—Ä–∏—Å–≤–æ–µ–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏, 
                —É—Ä–æ–≤–Ω–µ–º —Ä–∏—Å–∫–∞ –∏ –≥–ª–∞–≤–Ω—ã–º —Ñ–∞–∫—Ç–æ—Ä–æ–º —É–≥—Ä–æ–∑—ã. 
                –§–∞–π–ª –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤, —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏.
            </div>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.download_button(
        "–°–∫–∞—á–∞—Ç—å CSV —Å –º–µ—Ç–∫–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤",
        data=csv_bytes,
        file_name="vk_users_10000_clustered.csv",
        mime="text/csv",
        key="export_clusters",
        use_container_width=True
    )


# –î–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ:
# streamlit run vk_dasboard/modules/clustering.py
if __name__ == "__main__":
    st.set_page_config(
        page_title="–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è VK ‚Äî —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫",
        page_icon="",
        layout="wide",
        initial_sidebar_state="expanded",
    )
    page()
